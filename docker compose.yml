version: '3.8'

services:
    kafka:
        image: confluentinc/cp-kafka:7.5.0
        ports:
            - '9092:9092'
        environment:
            KAFKA_NODE_ID: 1
            KAFKA_PROCESS_ROLES: broker,controller
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
            KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        volumes:
            - kafka_data:/var/lib/kafka/data

    redis:
        image: redis:7-alpine
        ports:
            - '6379:6379'
        command: redis-server --maxmemory 1gb --maxmemory-policy allkeys-lru

    postgres:
        image: postgres:16-alpine
        environment:
            POSTGRES_DB: index
            POSTGRES_USER: scraper
            POSTGRES_PASSWORD: scraperpass
        ports:
            - '5432:5432'
        volumes:
            - postgres_data:/var/lib/postgresql/data

    scraper:
        build: .
        ports:
            - '9090:9090'
        environment:
            - KAFKA_BROKERS=kafka:9092
            - REDIS_URL=redis://redis:6379
            - DATABASE_URL=postgresql://scraper:scraperpass@postgres:5432/index
            - METRICS_PORT=9090
        depends_on:
            - kafka
            - redis
            - postgres
        deploy:
            resources:
                limits:
                    memory: 8G

    nginx:
        image: nginx:alpine
        ports:
            - '80:80'
        volumes:
            - ./frontend:/usr/share/nginx/html:ro
        depends_on:
            - scraper

volumes:
    postgres_data:
    kafka_data:
